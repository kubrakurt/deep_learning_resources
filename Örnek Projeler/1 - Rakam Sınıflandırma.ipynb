{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "* 10 kategoriye ayrılmış (0'dan 9'a kadar) elle yazılmış rakamlardan oluşan, siyah-beyaz renkte, 28x28 piksel görüntülerden oluşuyor.\n",
    "* 60.000 tanesi eğitim için, 10.000 tanesi test için olmak üzere toplamda 70.000 tane görüntü vardır.\n",
    "\n",
    "<p align = \"left\">\n",
    "    <img src=\"https://i1.wp.com/www.marktechpost.com/wp-content/uploads/2019/10/1_QAAGYDHreoRm4vEArNzTTQ.png?resize=372%2C238&ssl=1\" /></p>\n",
    "\n",
    "* Bu veriseti Keras üzerinde Numpy dizileri şeklinde yüklü halde gelmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **train_images** ve **train_labels** modelimizin öğrenmek için kullanacağı eğitim veri setini oluşturmaktadır.\n",
    "* **test_images** ve **test_labels** üzerinden de modelimizi test edeceğiz.\n",
    "* Görüntüler Numpy dizisi olarak kodlanmıştır.\n",
    "* Etiketler 0 ile 9 arasındaki rakamlardan oluşan birer dizidir.\n",
    "* Görüntüler ve etiketler arasında birebir ilişki vardır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Görüntü Seti Boyutu:   (60000, 28, 28) \n",
      "Train Etiket Seti Boyutu:    (60000,) \n",
      "Train Etiket Seti Görünümü:  [5 0 4 ... 5 6 8] \n",
      "\n",
      "Test Görüntü Seti Boyutu:    (10000, 28, 28) \n",
      "Test Etiket Seti Boyutu:     (10000,) \n",
      "Test Etiket Seti Görünümü:   [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Görüntü Seti Boyutu:  \", train_images.shape, \"\\n\"\n",
    "      \"Train Etiket Seti Boyutu:   \", train_labels.shape, \"\\n\"\n",
    "      \"Train Etiket Seti Görünümü: \", train_labels, \"\\n\")\n",
    "\n",
    "print(\"Test Görüntü Seti Boyutu:   \", test_images.shape, \"\\n\"\n",
    "      \"Test Etiket Seti Boyutu:    \", test_labels.shape, \"\\n\"\n",
    "      \"Test Etiket Seti Görünümü:  \", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Öncelikle Sinir Ağı'nı eğitim veri seti ile besleyeceğiz.\n",
    "* Ağ görüntüler ile etiketleri eşleştirmeyi öğrenecek.\n",
    "* Sonra **test setleri** ile ağı test edeceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ağ Mimarisi\n",
    "\n",
    "* Derin ağların temel yapı taşı, veri için filtre olarak düşünülebilecek veri işleme modülü olan katmanlardır.\n",
    "* Veri katmana ham hali girer ve daha kullanışlı formda çıkar.\n",
    "* Katmanlar kendisine verilen verilerden problemin çözümünde katkıda olacak daha anlamlı gösterimler çıkartmaya çalışırlar.\n",
    "* Derin öğrenmede öğrenme süreci çoğunlukla basit katmanları üst üste getirerek verinin ilerledikçe daha da arıtılmasını sağlayan yapıdadır.\n",
    "* Veri ilerledikçe daha da arıtıldığı birbirini takip eden süzgeçlere benzetilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models # Model\n",
    "from keras import layers # Katmanlar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modelimiz iki adet birbirini takip eden **Dense²** katmanı içeriyor.\n",
    "* İkinci (yani son katman) 10 adet çıktı birimi içermektedir.\n",
    "* Toplamları 1 olan 10 elemanlı olasılık puanları vardır.\n",
    "* Dizinin her bir elemanı o anki örneğimizdeki sayının 1'den 10'a kadar hangi sınıfa ait olduğunu gösteren bir olasılık değeridir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential() #Boş model oluşturuyoruz\n",
    "\n",
    "network.add(layers.Dense(512, activation=\"relu\", input_shape=(28*28,))) # Layers fonksiyonunu kullanarak dense katmanını ekliyoruz\n",
    "                                                                        # 512 tane eleman girişi yaptık\n",
    "                                                                        # Aktivasyon fonksiyonu olarak \"relu\" girişi yapıyoruz\n",
    "                                                                        # Boyut olarak da her bir görüntümüzün boyutu 28*28\n",
    "            \n",
    "network.add(layers.Dense(10, activation=\"softmax\")) # Sınıflandırıcı katmanını tekrar dense ile ekliyoruz\n",
    "                                                    # 0'dan 9'a kadar 10 sınıf vardır\n",
    "                                                    # Sınıflandırma için genellikle \"softmax\" seçiyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derleme Adımı\n",
    "\n",
    "Ağımızı eğitime hazır hale getirmek için 3 şeyi daha derleme adımı olarak almamız gerekiyor:\n",
    "\n",
    "* **Kayıp Fonksiyonu:** Ağızımın eğitim veri üzerinde kndi performansını gözlemlemesi ve böylece kendi kendine doğru yolu bulabilmesi içindir.\n",
    "* **Eniyileme:** Ağımızın girdisi olan veri ile oluşturduğu kaybı göz önünde bulundurarak kendisini güncelleme mekanizmasıdır.\n",
    "* **Eğitim ve test süresince takip edilecek metrikler:** Burada sadece doğruluğa (doğru sınıflandırılan görüntülerin toplam görüntü sayısına oranı) odaklanacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer olarak \"rmsprop\" kullanıyoruz\n",
    "# Kayıp fonksiyonu olarak \"categorical_crossentropy\" seçiyoruz\n",
    "# Metrik olarak da en çok tercih edilen \"accuracy\" kullanıyoruz\n",
    "\n",
    "network.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Girdilerin Hazırlanması\n",
    "\n",
    "* Eğitime başlamadan önce tüm girdiklerimizdeki değerleri [0,1] aralığına ölçeklendiriyoruz.\n",
    "* Bu aşamadan önce eğitim veri setimizdeki görüntüler (60000,28,28) şeklinde bir dizide ve her elemanı **uinit8** veri tipinde [0,255] veri aralığında saklanmıştı.\n",
    "* Eğitim veri setindeki görüntüleri (60000,28,28) **float32** veri tipinde [0,1] aralığında düzenliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype(\"float32\") / 255 # Normalizasyon (klasik olarak görüntü işlemede bu yapılır)\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiketlerin Hazırlanması\n",
    "\n",
    "* Verileri kategorik olarak dönüştürmemiz gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelin Eğitilmesi\n",
    "\n",
    "* Artık eğitime başlayabiliriz.\n",
    "* Bunun için **Keras**'ın **fit** metodunu çağırarak modelimizi eğitim veri setine uyduruyoruz.\n",
    "* Eğitim süresince iki değer gösterilecek.\n",
    "* Ağın eğitim veri seti üzerindeki kaybı ve doğruluğunu göreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.4289 - accuracy: 0.8763\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1099 - accuracy: 0.9681\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0708 - accuracy: 0.9790\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0501 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed475fc8b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eğitim setinde **0.9895** yani **%98.9**'luk bir doğruluğa ulaştık.\n",
    "* Şimdi test seti üzetinde deneyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 821us/step - loss: 0.0659 - accuracy: 0.9804\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eğitim setinin bir tık altında doğruluk elde ettik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.06588851660490036 \n",
      "test_acc: 0.980400025844574\n"
     ]
    }
   ],
   "source": [
    "print(\"test_loss:\", test_loss, \"\\n\"\n",
    "      \"test_acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
